---
title: "How and why do we measure variation"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(mosaic)
set.seed(123)
knitr::opts_chunk$set(echo = FALSE)
```


## Why do we measure variation?

### Introduction
Simply measuring the mean of a set of data does not give you any indication about
the **spread** of values in the data. There are a number of ways in which varibility
in the measurements can be calculated, and sometimes used to determine whether your
explanatory variables are affecting your response variables. We will focus on
several measures in this tutorial:

* sample mean
* sums of squares
* variance
* standard deviation
* standard error
* 95% confidence intervals

### Why do I need to know this?
You can drive a car without having to know exactly what a differential is doing,
what is a carburettor is for, or why the engine has a crankshaft. However, if you
have a basic understanding of its mechanics you'll find it easier to diagnose
faults _What is causing that squeaking from the rear axle?_, and avoid expensive
errors _Is it OK to put diesel in a petrol engine?_

![Which fuel should I use?](www/fuel_types.jpg)

The same applies to you as a quantitative biologist. You can't treat your models
as a mysterious black box into which you chuck data and some magic numbers are
returned. You need a basic understanding of how the models work and why, and this
will help you diagnose if anything goes wrong.

Don't worry, we'll keep the mathematics to a minimum, and use graphical and
interactive components where possible.
  

## Measures of central tendency

### What is 'central tendency'?
We are so familiar with some concepts, such as averages, that it is easy to
forget the biases implicit within the way in which they are calculate. For example,
if you listen to any politicians speaking, they will always talk about "the average
salary" that people are earning. This is not, however, the measure used by the
_Office for National Statistics_ (ONS) who actually collect the data. The latter
always prefer to use the "median salary". There is actually a big difference
between the two (about Â£5000 per year on current figures). The median salary is
what most people earn. The average salary is "distorted" by a relatively small
number of people earning incredibly high salaries (heads of FTSE100 companies 
etc.) and so doesn't represent what most people earn.

### Mean
This is the most commonly use measure of central tendency, i.e. take the sum of
all the values, and divide by the number of values. So that you are familiar with
algebraic notation, let's include the formula for a mean here, even though you
know how to calculate it:

$$\overline{x} = \frac{1}{n}\sum_{i = 1}^{n}x_i$$
Ehh?? How can calculating something as simple as an average look so horrific!!
Bear with me, because once you understand this equation, all the others fall
neatly into place.

* $\overline{x}$ = this is the mean, usually represented with a horizontal line above the symbol
* $n$ = the number of items of data
* $i$ = a counter. If you had five items of data ($n=5$), your counter $i$ will be 1, 2, 3, 4, 5
* $x_i$ = the value for each data point. So if you had five items of data, 6, 2, 1, 0, 8 
these would be $x_1 = 6$, $x_2 = 2$, $x_3 = 1$, $x_4 = 0$ and $x_5 = 8$
* $\sum$ = the Greek letter _sigma_ to indicate take the sum of a set of values
The subscript $i=1$ and superscript $n$ indicate to calculate the sum from your
first value where $i=1$ (the number 6 here) through every value up to your $n^{th}$
value (the fifth number, 8 in this example). Here $n = 5$ 
* $\frac{1}{n}$ = the reciprocal of $n$. Multiplying by the reciprocal of $n$ is
the same as dividing by $n$

To calculate a mean in R use the `mean()` function. If you want the mean broken
down by different categories of an explanatory variable, you can use the
syntax:

`mean(responsevar ~ categorical_explanatory, data=datasetname)`

**Need to add a simple exercise here**

### Median
The median is the value where 50% of your dataset is above the median, and
50% is below the median. It can be calculated using the `median()` function in R
with a similar syntax to above. If your data are normally distributed (bell-shaped
curve) the mean and median will be fairly similar:

```{r similar_mean_median}
 # generate 500 values at random with mean of 58
normal_distribution <- rnorm(500, mean=58)
gf_histogram(~ normal_distribution)
```

Mean = `r round(mean(normal_distribution), 2)`
Median = `r round(median(normal_distribution), 2)`

However, if the data are skewed, then the mean and median drift apart:

```{r dissimilar_mean_median}
# generate 500 values from a non-normal distribution
non_normal_distribution <- rlnorm(500, meanlog=log(58))
gf_histogram(~ non_normal_distribution)
```

Mean = `r round(mean(non_normal_distribution), 2)`
Median = `r round(median(non_normal_distribution), 2)`

Notice how in the skewed distribution, the median value gives a much more
representative indication of the 'central tendancy' than the mean, which was
distorted by a few very high values.

## Variability around the mean
Lets look at a set of data and think about how you might measure the variability
around the mean. Remember that in practice you often don't know what is causing
this variability in your data, but you still want to quantify it. Suppose you 
have the following 12 numbers from an experiment. This could all be from the
same treatment for example:

* 22.04 26.28 18.82 20.51 21.17 19.26 23.68 22.17 23.31 24.21 19.45 25.13

You can easily store these in an R object called `x` using the `c()` function
which _concatenates_ them all into a single object. Remember that just typing
the name of an R object will return its contents. Calculate the mean, median,
minumum and maximum values, and display a frequency histogram using the
`gf_histogram()` function:

```{r twelve_numbers, exercise = TRUE, code.completion = FALSE}
x <- c(22.04, 26.28, 18.82, 20.51, 21.17, 19.26, 23.68, 22.17, 23.31, 24.21, 19.45, 25.13)

```
```{r twelve_numbers-solution}
x # Display the contents of R object
mean(x)
median(x)
min(x)
max(x)
gf_histogram( ~ x)
```

You can see that the mean value is 22.17, so what is the best
way of measuring the variability around this mean? Before answering that
question, it is helpful to plot the data, from the first observation to twelveth
observation (numbers 1 to 12) along the x-axis, with the actual values for each
observation on the y-axis. We use a dotted horizontal line to show the overall
mean, and vertical lines above and below this to show how each observation 
varies.

```{r twelve_mean_and_deviations}
x <- c(22.04, 26.28, 18.82, 20.51, 21.17, 19.26, 23.68, 22.17, 23.31, 24.21, 19.45, 25.13)
tmp <- data.frame(cbind(xobsno=1:12, xobsval=x))
ggplot(aes(x=xobsno, y=xobsval), data=tmp) +
  geom_point() +
  geom_hline(yintercept = mean(tmp$xobsval), linetype = "dashed") +
  geom_segment(aes(x=xobsno, y=xobsval), xend = tmp$xobsno, yend = mean(tmp$xobsval)) +
  scale_x_continuous(breaks = 1:12) +
  xlab("Observation number from 1 to 12") +
  ylab("Recorded value for each observation") +
  theme_classic()
```

You can see that the 1st and 8th observations are very close to the overall
mean, whereas the 2nd, 6th, 11th and 12th observations are quite far from the
overall mean. Looking at this graph, think about the following question:

```{r how_to_measure_variation}
question("What do you think is the best way to measure the variability around this mean?",
         answer("Total of square roots of differences between mean and observed values",
                message = "Some of your differences are negative, and you cannot take
                the square root of a negative number"),
         answer("Total of differences between mean and observed values", message = "The
                differences from the mean are positive and negative. If you add up
                all these values you will obtain the answer zero"),
         answer("Total of squares of differences between mean and observed values",
                message = "Good. By squaring the differences before adding them
                together you remove the negative values (e.g. -3 x -3 = +9)", correct = TRUE),
         allow_retry = TRUE,
         random_answer_order = TRUE)
```


## The SS
Fortunately, in the context of quantitative biology, the SS stands for **sum of
squares** and has no unfortunate historical conotations. Simply be multiplying
each difference by itself before adding them together, you can calculate a 
measure of the variability. We can represent this algebraically as:

$$SS = \sum_{i = 1}^{n}(\overline{x}-x_i)^2$$
where

* $SS$ = sum of squares
* $\overline{x}$ = mean of your set of values, 22.17 on previous screen.
* $x_i$ = the value for each data point. We have 12 data points, $x_1 = 22.04$,
$x_2 = 26.28$, $x_3 = 18.82$, ..., $x_{12} = 25.13$
* $\sum$ =  Greek letter _sigma_ to indicate take the sum the squared differences

Note that the $\overline{x}-x_i$ part of the equation is inside brackets, before
squaring the results $(\overline{x}-x_i)^2$. This ensures that the difference is
calculated first, and then it is squared. If it had been written $\overline{x}-x_i^2$
you would obtain the wrong answer, as the observation value would have been squared
first, before being subtracted from the mean.

You can easily calculate the SS for a set of numbers in R. It is very unlikely
that you will ever have to do this, but some of your analysis outputs may include
a column headed 'SS' so it is useful to know what is going on. Using the twelve
numbers we had earlier, have a go at calculating the SS. There are 4 hints to
help you, the final one containing the solution, but try to have a go at working
it out yourself:

```{r calc_SS, exercise = TRUE, code.completion = FALSE}
x <- c(22.04, 26.28, 18.82, 20.51, 21.17, 19.26, 23.68, 22.17, 23.31, 24.21, 19.45, 25.13)

```

```{r calc_SS-hint-1}
# Subtract each observation from the mean
mean(x) - x
```

```{r calc_SS-hint-2}
# Remember to add brackets before squaring the differences
(mean(x) - x)
```

```{r calc_SS-hint-3}
# Use the ^2 to square the differences
(mean(x) - x)^2
```

```{r calc_SS-hint-4}
# Finally use the sum() function, requiring a second set of brackets
sum((mean(x) - x)^2)
```
