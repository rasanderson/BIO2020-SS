---
title: "How and why do we measure variation"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(mosaic)
set.seed(123)
knitr::opts_chunk$set(echo = FALSE)
```


## Why do we measure variation?

### Introduction
Simply measuring the mean of a set of data does not give you any indication about
the **spread** of values in the data. There are a number of ways in which varibility
in the measurements can be calculated, and sometimes used to determine whether your
explanatory variables are affecting your response variables. We will focus on
several measures in this tutorial:

* sample mean
* sums of squares
* variance
* standard deviation
* standard error
* 95% confidence intervals

### Why do I need to know this?
You can drive a car without having to know exactly what a differential is doing,
what is a carburettor is for, or why the engine has a crankshaft. However, if you
have a basic understanding of its mechanics you'll find it easier to diagnose
faults _What is causing that squeaking from the rear axle?_, and avoid expensive
errors _Is it OK to put diesel in a petrol engine?_

![Which fuel should I use?](www/fuel_types.jpg)

The same applies to you as a quantitative biologist. You can't treat your models
as a mysterious black box into which you chuck data and some magic numbers are
returned. You need a basic understanding of how the models work and why, and this
will help you diagnose if anything goes wrong.

Don't worry, we'll keep the mathematics to a minimum, and use graphical and
interactive components where possible.
  

## Measures of central tendency

### What is 'central tendency'?
We are so familiar with some concepts, such as averages, that it is easy to
forget the biases implicit within the way in which they are calculate. For example,
if you listen to any politicians speaking, they will always talk about "the average
salary" that people are earning. This is not, however, the measure used by the
_Office for National Statistics_ (ONS) who actually collect the data. The latter
always prefer to use the "median salary". There is actually a big difference
between the two (about Â£5000 per year on current figures). The median salary is
what most people earn. The average salary is "distorted" by a relatively small
number of people earning incredibly high salaries (heads of FTSE100 companies 
etc.) and so doesn't represent what most people earn.

### Mean
This is the most commonly use measure of central tendency, i.e. take the sum of
all the values, and divide by the number of values. So that you are familiar with
algebraic notation, let's include the formula for a mean here, even though you
know how to calculate it:

$$\overline{x} = \frac{1}{n}\sum_{i = 1}^{n}x_i$$
Ehh?? How can calculating something as simple as an average look so horrific!!
Bear with me, because once you understand this equation, all the others fall
neatly into place.

* $\overline{x}$ = this is the mean, usually represented with a horizontal line above the symbol
* $n$ = the number of items of data
* $i$ = a counter. If you had five items of data ($n=5$), your counter $i$ will be 1, 2, 3, 4, 5
* $x_i$ = the value for each data point. So if you had five items of data, 6, 2, 1, 0, 8 
these would be $x_1 = 6$, $x_2 = 2$, $x_3 = 1$, $x_4 = 0$ and $x_5 = 8$
* $\sum$ = the Greek letter _sigma_ to indicate take the sum of a set of values
The subscript $i=1$ and superscript $n$ indicate to calculate the sum from your
first value where $i=1$ (the number 6 here) through every value up to your $n^{th}$
value (the fifth number, 8 in this example). Here $n = 5$ 
* $\frac{1}{n}$ = the reciprocal of $n$. Multiplying by the reciprocal of $n$ is
the same as dividing by $n$

To calculate a mean in R use the `mean()` function. If you want the mean broken
down by different categories of an explanatory variable, you can use the
syntax:

`mean(responsevar ~ categorical_explanatory, data=datasetname)`

**Need to add a simple exercise here**

### Median
The median is the value where 50% of your dataset is above the median, and
50% is below the median. It can be calculated using the `median()` function in R
with a similar syntax to above. If your data are normally distributed (bell-shaped
curve) the mean and median will be fairly similar:

```{r similar_mean_median}
 # generate 500 values at random with mean of 58
normal_distribution <- rnorm(500, mean=58)
gf_histogram(~ normal_distribution)
```

Mean = `r round(mean(normal_distribution), 2)`
Median = `r round(median(normal_distribution), 2)`

However, if the data are skewed, then the mean and median drift apart:

```{r dissimilar_mean_median}
# generate 500 values from a non-normal distribution
non_normal_distribution <- rlnorm(500, meanlog=log(58))
gf_histogram(~ non_normal_distribution)
```

Mean = `r round(mean(non_normal_distribution), 2)`
Median = `r round(median(non_normal_distribution), 2)`


Notice how in the skewed distribution, the median value gives a much more
representative indication of the 'central tendancy' than the mean, which was
distorted by a few very high values.